{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from https://tfhub.dev/google/universal-sentence-encoder/2\n",
      "Reading data from files...\n",
      "Reading file for Bruce Banner\n",
      "Reading file for Bucky Barners\n",
      "Reading file for child of thanos\n",
      "Reading file for Collector\n",
      "Reading file for Corvus Glaive\n",
      "Reading file for Doctor Strange\n",
      "Reading file for Dome Control\n",
      "Reading file for Drax\n",
      "Reading file for Ebony Maw\n",
      "Reading file for Eitri\n",
      "Reading file for F.R.I.D.A.Y\n",
      "Reading file for Gamora's Mother\n",
      "Reading file for Gamora\n",
      "Reading file for Groot\n",
      "Reading file for Heimdall\n",
      "Reading file for Hulk\n",
      "Reading file for Jabari Warriors\n",
      "Reading file for Jabari\n",
      "Reading file for James Rhodey\n",
      "Reading file for Loki\n",
      "Reading file for M'Baku\n",
      "Reading file for Mantis\n",
      "Reading file for Maria Hill\n",
      "Reading file for Memory Gamora\n",
      "Reading file for Natasha Romanoff\n",
      "Reading file for Nebula\n",
      "Reading file for Ned Leeds\n",
      "Reading file for Nick Fury\n",
      "Reading file for Okoye\n",
      "Reading file for Pepper Pots\n",
      "Reading file for Peter Parker\n",
      "Reading file for Proxima Midnight\n",
      "Reading file for Red Skull\n",
      "Reading file for Rocket\n",
      "Reading file for Sam Wilson\n",
      "Reading file for Scarlett Witch\n",
      "Reading file for Secretary Ross\n",
      "Reading file for Shuri\n",
      "Reading file for Stan Lee\n",
      "Reading file for Starlord\n",
      "Reading file for Steve Rogers\n",
      "Reading file for Stone Keeper\n",
      "Reading file for T'Challa\n",
      "Reading file for Thanos\n",
      "Reading file for Thor\n",
      "Reading file for Tony Stark\n",
      "Reading file for Vision\n",
      "Reading file for Wong\n",
      "================================\n",
      "Characters selected:\n",
      "0: Bruce Banner\n",
      "1: Collector\n",
      "2: Corvus Glaive\n",
      "3: Doctor Strange\n",
      "4: Dome Control\n",
      "5: Drax\n",
      "6: Ebony Maw\n",
      "7: Eitri\n",
      "8: F.R.I.D.A.Y\n",
      "9: Gamora's Mother\n",
      "10: Gamora\n",
      "11: Groot\n",
      "12: Heimdall\n",
      "13: Hulk\n",
      "14: Jabari Warriors\n",
      "15: Jabari\n",
      "16: James Rhodey\n",
      "17: Loki\n",
      "18: M'Baku\n",
      "19: Mantis\n",
      "20: Maria Hill\n",
      "21: Memory Gamora\n",
      "22: Natasha Romanoff\n",
      "23: Nebula\n",
      "24: Ned Leeds\n",
      "25: Nick Fury\n",
      "26: Okoye\n",
      "27: Pepper Pots\n",
      "28: Peter Parker\n",
      "29: Proxima Midnight\n",
      "30: Red Skull\n",
      "31: Rocket\n",
      "32: Sam Wilson\n",
      "33: Scarlett Witch\n",
      "34: Secretary Ross\n",
      "35: Shuri\n",
      "36: Stan Lee\n",
      "37: Starlord\n",
      "38: Steve Rogers\n",
      "39: Stone Keeper\n",
      "40: T'Challa\n",
      "41: Thanos\n",
      "42: Thor\n",
      "43: Tony Stark\n",
      "44: Vision\n",
      "45: Wong\n",
      "================================\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "\n",
    "print(\"Loading model from {}\".format(module_url))\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "text_files = [f for f in os.listdir() if f.endswith(\".txt\")]\n",
    "\n",
    "#characters = [i[:-4] for i in text_files]\n",
    "character_lines = {}\n",
    "\n",
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(corr,\\\n",
    "        #xticklabels=labels,\\\n",
    "        #yticklabels=labels,\\\n",
    "        vmin=0,\\\n",
    "        vmax=1,\\\n",
    "        cmap=\"YlOrRd\")\n",
    "    #g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "    #figure = g.get_figure()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Avenger-semantic-similarity.png\")\n",
    "    plt.show()\n",
    "\n",
    "def run_and_plot(session_, input_tensor_, messages_, labels_, encoding_tensor):\n",
    "    message_embeddings_ = session_.run(encoding_tensor, feed_dict={input_tensor_: messages_})\n",
    "    plot_similarity(labels_, message_embeddings_, 90)\n",
    "\n",
    "print(\"Reading data from files...\")\n",
    "\n",
    "for fname in text_files:\n",
    "    character = fname[:-4]\n",
    "    print(\"Reading file for {}\".format(character))\n",
    "    character_line = \"\"\n",
    "    with open(fname,'r') as g:\n",
    "        for line in g.readlines():\n",
    "            character_line+=line.strip()\n",
    "        if character_line == \"\":\n",
    "            continue\n",
    "        character_lines[character]=character_line\n",
    "\n",
    "# # Select characters\n",
    "# print(\"================================\")\n",
    "# print(\"Characters found:\")\n",
    "# for i in range(len(character_lines.keys())):\n",
    "#     print(\"{}: {}\".format(i,list(character_lines.keys())[i]))\n",
    "# print(\"================================\")\n",
    "# print(\"Enter character index to be used:\")\n",
    "# print(\"Enter q or Q to stop.\")\n",
    "# flag = True\n",
    "# char_index = \"\"\n",
    "# final_character_lines = {}\n",
    "# characters = list(character_lines.keys())\n",
    "# while flag:\n",
    "#     char_index = input()\n",
    "#     if char_index.upper() == 'Q':\n",
    "#         flag=False\n",
    "#     else:\n",
    "#         char_index = int(char_index)\n",
    "#         final_character_lines[characters[char_index]]=character_lines[characters[char_index]]\n",
    "\n",
    "# #character_lines = final_character_lines\n",
    "\n",
    "print(\"================================\")\n",
    "print(\"Characters selected:\")\n",
    "for i in range(len(character_lines.keys())):\n",
    "    print(\"{}: {}\".format(i,list(character_lines.keys())[i]))\n",
    "print(\"================================\")\n",
    "\n",
    "\n",
    "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "similarity_message_encodings = embed(similarity_input_placeholder)\n",
    "#similarity_labels_placeholder= tf.placeholder(\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    run_and_plot(session, similarity_input_placeholder,\\\n",
    "            list(character_lines.values()),\\\n",
    "            list(character_lines.keys()),\\\n",
    "            similarity_message_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
